{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "24289325",
   "metadata": {},
   "source": [
    "# Trustpilot Feedback Analyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3cc37a",
   "metadata": {},
   "source": [
    "#### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c435aae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from reader import feed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698667a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#soup.find_all('article', class_=\"paper_paper__1PY90 paper_square__lJX8a card_card__lQWDv styles_reviewCard__hcAvl\")\n",
    "#ptags = soup.select('div > p')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df048b67",
   "metadata": {},
   "source": [
    "### Scrapper 1 - For Loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18e3578e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-09T11:15:42.000Z</td>\n",
       "      <td>Mag. Christine M.</td>\n",
       "      <td>Super Verkauf: Nach meinen nicht so guten Erfa...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-09T10:10:15.000Z</td>\n",
       "      <td>Irmgard Wettering</td>\n",
       "      <td>Immer freundlich egal wie oft ich angerufen ha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-09T01:33:06.000Z</td>\n",
       "      <td>Hans Dampf</td>\n",
       "      <td>Diese Firma scheint sich darauf spezialisiert ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-08T16:28:47.000Z</td>\n",
       "      <td>Michael Behrndt</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-08T13:02:20.000Z</td>\n",
       "      <td>Kersten Bienick</td>\n",
       "      <td>Den einen Stern gibt es für die freundliche Ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4039</th>\n",
       "      <td>2017-10-27T10:02:48.000Z</td>\n",
       "      <td>FAmer</td>\n",
       "      <td>Hatte jetzt schon mehrere Zusammenarbeiten  mi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4040</th>\n",
       "      <td>2017-10-26T09:12:45.000Z</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>Ich hatte einen netten Kontakt mit mcmakler</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4041</th>\n",
       "      <td>2017-10-06T14:41:48.000Z</td>\n",
       "      <td>M. H.</td>\n",
       "      <td>Top Unterlagen, viel Kompetenz und endlich mal...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>2017-04-20T08:54:46.000Z</td>\n",
       "      <td>A. Graf</td>\n",
       "      <td>Sehr freundliches Gespräch mit Herrn Wegner - ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4043</th>\n",
       "      <td>2015-09-17T14:49:38.482Z</td>\n",
       "      <td>J.B.</td>\n",
       "      <td>Kaum hatte ich meine Anzeige bei Immobiliensco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4044 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date           reviewer  \\\n",
       "0     2022-04-09T11:15:42.000Z  Mag. Christine M.   \n",
       "1     2022-04-09T10:10:15.000Z  Irmgard Wettering   \n",
       "2     2022-04-09T01:33:06.000Z         Hans Dampf   \n",
       "3     2022-04-08T16:28:47.000Z    Michael Behrndt   \n",
       "4     2022-04-08T13:02:20.000Z    Kersten Bienick   \n",
       "...                        ...                ...   \n",
       "4039  2017-10-27T10:02:48.000Z              FAmer   \n",
       "4040  2017-10-26T09:12:45.000Z             Sandra   \n",
       "4041  2017-10-06T14:41:48.000Z              M. H.   \n",
       "4042  2017-04-20T08:54:46.000Z            A. Graf   \n",
       "4043  2015-09-17T14:49:38.482Z               J.B.   \n",
       "\n",
       "                                                   text stars  \n",
       "0     Super Verkauf: Nach meinen nicht so guten Erfa...     5  \n",
       "1     Immer freundlich egal wie oft ich angerufen ha...     5  \n",
       "2     Diese Firma scheint sich darauf spezialisiert ...     1  \n",
       "3                                                           5  \n",
       "4     Den einen Stern gibt es für die freundliche Ar...     1  \n",
       "...                                                 ...   ...  \n",
       "4039  Hatte jetzt schon mehrere Zusammenarbeiten  mi...     5  \n",
       "4040        Ich hatte einen netten Kontakt mit mcmakler     5  \n",
       "4041  Top Unterlagen, viel Kompetenz und endlich mal...     5  \n",
       "4042  Sehr freundliches Gespräch mit Herrn Wegner - ...     5  \n",
       "4043  Kaum hatte ich meine Anzeige bei Immobiliensco...     1  \n",
       "\n",
       "[4044 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Options for Company Name\n",
    "company = input()\n",
    "\n",
    "query_url = \"https://www.trustpilot.com/search?query=\"+company\n",
    "\n",
    "choice_request = requests.get(query_url)\n",
    "choice = BeautifulSoup(choice_request.text, 'html.parser')\n",
    "options = choice.select('div > h3 > a')\n",
    "\n",
    "url_choice=[]\n",
    "for o in range(len(options)):\n",
    "    url_choice.append(\"https://www.trustpilot.com\"+options[o]['href']+\"?languages=de\")\n",
    "\n",
    "# Let user choose from list of options\n",
    "\n",
    "# Use the selected Company\n",
    "url_chosen = url_choice[1]  #MAKE IT FLEXIBLE LATER!\n",
    "count_request = requests.get(url_chosen)\n",
    "soup_init = BeautifulSoup(count_request.text, 'html.parser')\n",
    "\n",
    "# Get number of feedback pages for website\n",
    "pages=int(soup_init.select('#__next > div > main > div > div.styles_mainContent__nFxAv > section > div.styles_pagination__6VmQv > nav > a:nth-child(8)')[0]['aria-label'][12:])\n",
    "pages\n",
    "\n",
    "# Get list of all URLs to Scrape\n",
    "urllist=[]\n",
    "for p in range(1,pages+1):\n",
    "    if p == 1:\n",
    "        urllist.append(url_chosen)\n",
    "    else:\n",
    "        urllist.append(url_chosen+\"&page=\"+str(p))\n",
    "\n",
    "# Loop through urllist to scrape all pages\n",
    "revlist = []   \n",
    "namelist = []\n",
    "titlelist = []   \n",
    "ratlist = []\n",
    "datelist = []\n",
    "\n",
    "for u in urllist:\n",
    "    test = requests.get(u)\n",
    "    feedbacksoup = BeautifulSoup(test.text, 'html.parser')\n",
    "\n",
    "    # Get Names of Reviewers\n",
    "    nametags= feedbacksoup.select('article > aside > div > a > div:first-child')\n",
    "    for n in nametags:\n",
    "        namelist.append(n.get_text())\n",
    "\n",
    "    #namelist = [ n.get_text() for n in nametags for u in urllist] : check nested for loops in list comprehensions Check out library \"os\" to know the date of the file.\n",
    "\n",
    "    # GET FEEDBACK CONTENT\n",
    "    content=feedbacksoup.find_all('div', class_=\"styles_reviewContent__0Q2Tg\")\n",
    "    for p in content:\n",
    "        revlist.append(p.get_text())\n",
    "\n",
    "    # Get Titles and clean it from the Review Content\n",
    "    titles = feedbacksoup.select('div > h2') \n",
    "    for t in titles[2:]:\n",
    "        titlelist.append(len(t.get_text()))\n",
    "\n",
    "    # GET REVIEW STARS\n",
    "    ratings=feedbacksoup.find_all('div', class_=\"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\")\n",
    "\n",
    "    for r in ratings[1:]:\n",
    "        ratlist.append(\"\\n\".join([img['alt'][6:7] for img in r.find_all('img', alt=True)])) #6:7 marks the position of the stars rating\n",
    "        \n",
    "    # Get Feedback Date\n",
    "    dates = feedbacksoup.find_all('time', class_=\"\")\n",
    "    for d in dates:\n",
    "        datelist.append(d['datetime'])\n",
    "\n",
    "# Create Final Dataframe with all information of the Feedbacks\n",
    "review_df = pd.DataFrame({\"date\":datelist,\"reviewer\":namelist,\"text\":revlist, \"stars\":ratlist})\n",
    "\n",
    "\n",
    "# Basic Cleaning of scraped data\n",
    "clean_content = []\n",
    "for text, kill in zip(review_df['text'],titlelist):\n",
    "    clean_content.append(text[kill:])\n",
    "\n",
    "review_df['text']=clean_content\n",
    "display(review_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e9beb",
   "metadata": {},
   "source": [
    "### Scrapper 2 - List Comprehensions (bad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "147c2194",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/robertkammerer/Ironhack/Final Project/Trustpilot Scrapper_v2.ipynb Cell 8'\u001b[0m in \u001b[0;36m<cell line: 47>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=43'>44</a>\u001b[0m namelist \u001b[39m=\u001b[39m [feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39marticle > aside > div > a > div:first-child\u001b[39m\u001b[39m'\u001b[39m)[n]\u001b[39m.\u001b[39mget_text() \u001b[39mfor\u001b[39;00m lp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39marticle > aside > div > a > div:first-child\u001b[39m\u001b[39m'\u001b[39m)))]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=45'>46</a>\u001b[0m \u001b[39m# GET FEEDBACK CONTENT\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=46'>47</a>\u001b[0m revlist \u001b[39m=\u001b[39m [feedbacksoup[lp]\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstyles_reviewContent__0Q2Tg\u001b[39m\u001b[39m\"\u001b[39m)[r]\u001b[39m.\u001b[39mget_text() \u001b[39mfor\u001b[39;00m lp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup)) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstyles_reviewContent__0Q2Tg\u001b[39m\u001b[39m\"\u001b[39m)))]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=48'>49</a>\u001b[0m \u001b[39m# Get Titles and clean it from the Review Content\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=49'>50</a>\u001b[0m titlelist \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39mdiv > h2\u001b[39m\u001b[39m'\u001b[39m)[t]\u001b[39m.\u001b[39mget_text()) \u001b[39mfor\u001b[39;00m lp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup)) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39mdiv > h2\u001b[39m\u001b[39m'\u001b[39m)))[\u001b[39m2\u001b[39m:]]\n",
      "\u001b[1;32m/Users/robertkammerer/Ironhack/Final Project/Trustpilot Scrapper_v2.ipynb Cell 8'\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=43'>44</a>\u001b[0m namelist \u001b[39m=\u001b[39m [feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39marticle > aside > div > a > div:first-child\u001b[39m\u001b[39m'\u001b[39m)[n]\u001b[39m.\u001b[39mget_text() \u001b[39mfor\u001b[39;00m lp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup)) \u001b[39mfor\u001b[39;00m n \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39marticle > aside > div > a > div:first-child\u001b[39m\u001b[39m'\u001b[39m)))]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=45'>46</a>\u001b[0m \u001b[39m# GET FEEDBACK CONTENT\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=46'>47</a>\u001b[0m revlist \u001b[39m=\u001b[39m [feedbacksoup[lp]\u001b[39m.\u001b[39;49mfind_all(\u001b[39m'\u001b[39;49m\u001b[39mdiv\u001b[39;49m\u001b[39m'\u001b[39;49m, class_\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mstyles_reviewContent__0Q2Tg\u001b[39;49m\u001b[39m\"\u001b[39;49m)[r]\u001b[39m.\u001b[39mget_text() \u001b[39mfor\u001b[39;00m lp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup)) \u001b[39mfor\u001b[39;00m r \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mfind_all(\u001b[39m'\u001b[39m\u001b[39mdiv\u001b[39m\u001b[39m'\u001b[39m, class_\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mstyles_reviewContent__0Q2Tg\u001b[39m\u001b[39m\"\u001b[39m)))]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=48'>49</a>\u001b[0m \u001b[39m# Get Titles and clean it from the Review Content\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/robertkammerer/Ironhack/Final%20Project/Trustpilot%20Scrapper_v2.ipynb#ch0000007?line=49'>50</a>\u001b[0m titlelist \u001b[39m=\u001b[39m [\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39mdiv > h2\u001b[39m\u001b[39m'\u001b[39m)[t]\u001b[39m.\u001b[39mget_text()) \u001b[39mfor\u001b[39;00m lp \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup)) \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(feedbacksoup[lp]\u001b[39m.\u001b[39mselect(\u001b[39m'\u001b[39m\u001b[39mdiv > h2\u001b[39m\u001b[39m'\u001b[39m)))[\u001b[39m2\u001b[39m:]]\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py:1892\u001b[0m, in \u001b[0;36mTag.find_all\u001b[0;34m(self, name, attrs, recursive, string, limit, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=1889'>1890</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m recursive:\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=1890'>1891</a>\u001b[0m     generator \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchildren\n\u001b[0;32m-> <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=1891'>1892</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_find_all(name, attrs, string, limit, generator, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py:827\u001b[0m, in \u001b[0;36mPageElement._find_all\u001b[0;34m(self, name, attrs, string, limit, generator, **kwargs)\u001b[0m\n\u001b[1;32m    <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=824'>825</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=825'>826</a>\u001b[0m \u001b[39mif\u001b[39;00m i:\n\u001b[0;32m--> <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=826'>827</a>\u001b[0m     found \u001b[39m=\u001b[39m strainer\u001b[39m.\u001b[39;49msearch(i)\n\u001b[1;32m    <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=827'>828</a>\u001b[0m     \u001b[39mif\u001b[39;00m found:\n\u001b[1;32m    <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=828'>829</a>\u001b[0m         results\u001b[39m.\u001b[39mappend(found)\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py:2181\u001b[0m, in \u001b[0;36mSoupStrainer.search\u001b[0;34m(self, markup)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2178'>2179</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(markup, Tag):\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2179'>2180</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstring \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattrs:\n\u001b[0;32m-> <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2180'>2181</a>\u001b[0m         found \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msearch_tag(markup)\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2181'>2182</a>\u001b[0m \u001b[39m# If it's text, make sure the text matches.\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2182'>2183</a>\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(markup, NavigableString) \u001b[39mor\u001b[39;00m \\\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2183'>2184</a>\u001b[0m          \u001b[39misinstance\u001b[39m(markup, \u001b[39mstr\u001b[39m):\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py:2144\u001b[0m, in \u001b[0;36mSoupStrainer.search_tag\u001b[0;34m(self, markup_name, markup_attrs)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2141'>2142</a>\u001b[0m             markup_attr_map[k] \u001b[39m=\u001b[39m v\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2142'>2143</a>\u001b[0m attr_value \u001b[39m=\u001b[39m markup_attr_map\u001b[39m.\u001b[39mget(attr)\n\u001b[0;32m-> <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2143'>2144</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_matches(attr_value, match_against):\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2144'>2145</a>\u001b[0m     match \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2145'>2146</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py:2204\u001b[0m, in \u001b[0;36mSoupStrainer._matches\u001b[0;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2199'>2200</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2200'>2201</a>\u001b[0m \u001b[39m# We didn't match any particular value of the multivalue\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2201'>2202</a>\u001b[0m \u001b[39m# attribute, but maybe we match the attribute value when\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2202'>2203</a>\u001b[0m \u001b[39m# considered as a string.\u001b[39;00m\n\u001b[0;32m-> <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2203'>2204</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_matches(\u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(markup), match_against):\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2204'>2205</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2205'>2206</a>\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py:2260\u001b[0m, in \u001b[0;36mSoupStrainer._matches\u001b[0;34m(self, markup, match_against, already_tried)\u001b[0m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2255'>2256</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m match \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(match_against, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2256'>2257</a>\u001b[0m     \u001b[39m# Exact string match\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2257'>2258</a>\u001b[0m     match \u001b[39m=\u001b[39m markup \u001b[39m==\u001b[39m match_against\n\u001b[0;32m-> <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2259'>2260</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m match \u001b[39mand\u001b[39;00m \u001b[39mhasattr\u001b[39;49m(match_against, \u001b[39m'\u001b[39;49m\u001b[39msearch\u001b[39;49m\u001b[39m'\u001b[39;49m):\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2260'>2261</a>\u001b[0m     \u001b[39m# Regexp match\u001b[39;00m\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2261'>2262</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m match_against\u001b[39m.\u001b[39msearch(markup)\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2263'>2264</a>\u001b[0m \u001b[39mif\u001b[39;00m (\u001b[39mnot\u001b[39;00m match\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2264'>2265</a>\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(original_markup, Tag)\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2265'>2266</a>\u001b[0m     \u001b[39mand\u001b[39;00m original_markup\u001b[39m.\u001b[39mprefix):\n\u001b[1;32m   <a href='file:///Users/robertkammerer/opt/anaconda3/envs/finalproject/lib/python3.10/site-packages/bs4/element.py?line=2266'>2267</a>\u001b[0m     \u001b[39m# Try the whole thing again with the prefixed tag name.\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Get Options for Company Name\n",
    "company = input()\n",
    "\n",
    "query_url = \"https://www.trustpilot.com/search?query=\"+company\n",
    "\n",
    "choice_request = requests.get(query_url)\n",
    "choice = BeautifulSoup(choice_request.text, 'html.parser')\n",
    "options = choice.select('div > h3 > a')\n",
    "\n",
    "url_choice=[]\n",
    "for o in range(len(options)):\n",
    "    url_choice.append(\"https://www.trustpilot.com\"+options[o]['href']+\"?languages=de\")\n",
    "\n",
    "# Let user choose from list of options\n",
    "\n",
    "# Use the selected Company\n",
    "url_chosen = url_choice[1]  #MAKE IT FLEXIBLE LATER!\n",
    "count_request = requests.get(url_chosen)\n",
    "soup_init = BeautifulSoup(count_request.text, 'html.parser')\n",
    "\n",
    "# Get number of feedback pages for website\n",
    "pages=int(soup_init.select('#__next > div > main > div > div.styles_mainContent__nFxAv > section > div.styles_pagination__6VmQv > nav > a:nth-child(8)')[0]['aria-label'][12:])\n",
    "pages\n",
    "\n",
    "# Get list of all URLs to Scrape\n",
    "urllist=[]\n",
    "for p in range(1,pages+1):\n",
    "    if p == 1:\n",
    "        urllist.append(url_chosen)\n",
    "    else:\n",
    "        urllist.append(url_chosen+\"&page=\"+str(p))\n",
    "\n",
    "# Loop through urllist to scrape all pages  \n",
    "\n",
    "###---\n",
    "feedbacksoup = [  BeautifulSoup(requests.get(u).text, 'html.parser') for u in urllist]  \n",
    "\n",
    "#print(len(feedbacksoup))\n",
    "\n",
    "# Get Feedback Date\n",
    "datelist = [ feedbacksoup[lp].find_all('time', class_=\"\")[d]['datetime'] for lp in range(len(feedbacksoup)) for d in range(len(feedbacksoup[lp].find_all('time', class_=\"\")))   ]\n",
    "\n",
    "# Get Names of Reviewers\n",
    "namelist = [feedbacksoup[lp].select('article > aside > div > a > div:first-child')[n].get_text() for lp in range(len(feedbacksoup)) for n in range(len(feedbacksoup[lp].select('article > aside > div > a > div:first-child')))]\n",
    "\n",
    "# GET FEEDBACK CONTENT\n",
    "revlist = [feedbacksoup[lp].find_all('div', class_=\"styles_reviewContent__0Q2Tg\")[r].get_text() for lp in range(len(feedbacksoup)) for r in range(len(feedbacksoup[lp].find_all('div', class_=\"styles_reviewContent__0Q2Tg\")))]\n",
    "\n",
    "# Get Titles and clean it from the Review Content\n",
    "titlelist = [len(feedbacksoup[lp].select('div > h2')[t].get_text()) for lp in range(len(feedbacksoup)) for t in range(len(feedbacksoup[lp].select('div > h2')))[2:]]\n",
    "\n",
    "# GET REVIEW STARS\n",
    "\n",
    "ratlist = [(\"\\n\".join([img['alt'][6:7] for img in feedbacksoup[lp].find_all('div', class_=\"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\")[r].find_all('img', alt=True)]))\n",
    " for lp in range(len(feedbacksoup)) for r in range(len(feedbacksoup[lp].find_all('div', class_=\"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\")[1:]))]\n",
    "\n",
    "\n",
    "# Create Final Dataframe with all information of the Feedbacks\n",
    "review_df = pd.DataFrame({\"date\":datelist,\"reviewer\":namelist,\"text\":revlist, \"stars\":ratlist})\n",
    "\n",
    "\n",
    "\n",
    "# Basic Cleaning of scraped data\n",
    "clean_content = []\n",
    "for text, kill in zip(review_df['text'],titlelist):\n",
    "    clean_content.append(text[kill:])\n",
    "\n",
    "review_df['text']=clean_content\n",
    "display(review_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d33ce2b4",
   "metadata": {},
   "source": [
    "### Scrapper 3 - List Comprehension (better)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "58c96ed4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-04-09T11:15:42.000Z</td>\n",
       "      <td>Mag. Christine M.</td>\n",
       "      <td>Super Verkauf: Nach meinen nicht so guten Erfa...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-04-09T10:10:15.000Z</td>\n",
       "      <td>Irmgard Wettering</td>\n",
       "      <td>Immer freundlich egal wie oft ich angerufen ha...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-04-09T01:33:06.000Z</td>\n",
       "      <td>Hans Dampf</td>\n",
       "      <td>Diese Firma scheint sich darauf spezialisiert ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-04-08T16:28:47.000Z</td>\n",
       "      <td>Michael Behrndt</td>\n",
       "      <td></td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-04-08T13:02:20.000Z</td>\n",
       "      <td>Kersten Bienick</td>\n",
       "      <td>Den einen Stern gibt es für die freundliche Ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2059</th>\n",
       "      <td>2017-10-27T10:02:48.000Z</td>\n",
       "      <td>FAmer</td>\n",
       "      <td>Hatte jetzt schon mehrere Zusammenarbeiten  mi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2060</th>\n",
       "      <td>2017-10-26T09:12:45.000Z</td>\n",
       "      <td>Sandra</td>\n",
       "      <td>Ich hatte einen netten Kontakt mit mcmakler</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2061</th>\n",
       "      <td>2017-10-06T14:41:48.000Z</td>\n",
       "      <td>M. H.</td>\n",
       "      <td>Top Unterlagen, viel Kompetenz und endlich mal...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2062</th>\n",
       "      <td>2017-04-20T08:54:46.000Z</td>\n",
       "      <td>A. Graf</td>\n",
       "      <td>Sehr freundliches Gespräch mit Herrn Wegner - ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2063</th>\n",
       "      <td>2015-09-17T14:49:38.482Z</td>\n",
       "      <td>J.B.</td>\n",
       "      <td>Kaum hatte ich meine Anzeige bei Immobiliensco...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2064 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          date           reviewer  \\\n",
       "0     2022-04-09T11:15:42.000Z  Mag. Christine M.   \n",
       "1     2022-04-09T10:10:15.000Z  Irmgard Wettering   \n",
       "2     2022-04-09T01:33:06.000Z         Hans Dampf   \n",
       "3     2022-04-08T16:28:47.000Z    Michael Behrndt   \n",
       "4     2022-04-08T13:02:20.000Z    Kersten Bienick   \n",
       "...                        ...                ...   \n",
       "2059  2017-10-27T10:02:48.000Z              FAmer   \n",
       "2060  2017-10-26T09:12:45.000Z             Sandra   \n",
       "2061  2017-10-06T14:41:48.000Z              M. H.   \n",
       "2062  2017-04-20T08:54:46.000Z            A. Graf   \n",
       "2063  2015-09-17T14:49:38.482Z               J.B.   \n",
       "\n",
       "                                                   text stars  \n",
       "0     Super Verkauf: Nach meinen nicht so guten Erfa...     5  \n",
       "1     Immer freundlich egal wie oft ich angerufen ha...     5  \n",
       "2     Diese Firma scheint sich darauf spezialisiert ...     1  \n",
       "3                                                           5  \n",
       "4     Den einen Stern gibt es für die freundliche Ar...     1  \n",
       "...                                                 ...   ...  \n",
       "2059  Hatte jetzt schon mehrere Zusammenarbeiten  mi...     5  \n",
       "2060        Ich hatte einen netten Kontakt mit mcmakler     5  \n",
       "2061  Top Unterlagen, viel Kompetenz und endlich mal...     5  \n",
       "2062  Sehr freundliches Gespräch mit Herrn Wegner - ...     5  \n",
       "2063  Kaum hatte ich meine Anzeige bei Immobiliensco...     1  \n",
       "\n",
       "[2064 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Options for Company Name\n",
    "company = input()\n",
    "\n",
    "query_url = \"https://www.trustpilot.com/search?query=\"+company\n",
    "\n",
    "choice_request = requests.get(query_url)\n",
    "choice = BeautifulSoup(choice_request.text, 'html.parser')\n",
    "options = choice.select('div > h3 > a')\n",
    "\n",
    "url_choice=[]\n",
    "for o in range(len(options)):\n",
    "    url_choice.append(\"https://www.trustpilot.com\"+options[o]['href']+\"?languages=de\")\n",
    "\n",
    "# Let user choose from list of options\n",
    "\n",
    "# Use the selected Company\n",
    "url_chosen = url_choice[1]  #MAKE IT FLEXIBLE LATER!\n",
    "count_request = requests.get(url_chosen)\n",
    "soup_init = BeautifulSoup(count_request.text, 'html.parser')\n",
    "\n",
    "# Get number of feedback pages for website\n",
    "pages=int(soup_init.select('#__next > div > main > div > div.styles_mainContent__nFxAv > section > div.styles_pagination__6VmQv > nav > a:nth-child(8)')[0]['aria-label'][12:])\n",
    "pages\n",
    "\n",
    "# Get list of all URLs to Scrape\n",
    "urllist=[]\n",
    "for p in range(1,pages+1):\n",
    "    if p == 1:\n",
    "        urllist.append(url_chosen)\n",
    "    else:\n",
    "        urllist.append(url_chosen+\"&page=\"+str(p))\n",
    "\n",
    "# Loop through urllist to scrape all pages\n",
    "revlist = []   \n",
    "namelist = []\n",
    "titlelist = []   \n",
    "ratlist = []\n",
    "datelist = []\n",
    "\n",
    "for u in urllist:\n",
    "    test = requests.get(u)\n",
    "    feedbacksoup = BeautifulSoup(test.text, 'html.parser')\n",
    "\n",
    "    # Get Names of Reviewers\n",
    "    nametags= feedbacksoup.select('article > aside > div > a > div:first-child')\n",
    "    namelist.extend([n.get_text() for n in nametags])\n",
    "\n",
    "    # GET FEEDBACK CONTENT\n",
    "    content=feedbacksoup.find_all('div', class_=\"styles_reviewContent__0Q2Tg\")\n",
    "    revlist.extend([p.get_text() for p in content])\n",
    "\n",
    "    # Get Titles and clean it from the Review Content\n",
    "    titles = feedbacksoup.select('div > h2') \n",
    "    titlelist.extend([len(t.get_text()) for t in titles[2:]])\n",
    "\n",
    "    # GET REVIEW STARS\n",
    "    ratings=feedbacksoup.find_all('div', class_=\"star-rating_starRating__4rrcf star-rating_medium__iN6Ty\")\n",
    "    ratlist.extend([\"\\n\".join([img['alt'][6:7] for img in r.find_all('img', alt=True)]) for r in ratings[1:]])\n",
    "        \n",
    "    # Get Feedback Date\n",
    "    dates = feedbacksoup.find_all('time', class_=\"\")\n",
    "    datelist.extend([d['datetime'] for d in dates])\n",
    "\n",
    "# Create Final Dataframe with all information of the Feedbacks\n",
    "review_df = pd.DataFrame({\"date\":datelist,\"reviewer\":namelist,\"text\":revlist, \"stars\":ratlist})\n",
    "\n",
    "# Cleaning of Text by getting rid of the title out of the text (often duplicate of the beginning of the text)\n",
    "clean_content = []\n",
    "for text, kill in zip(review_df['text'],titlelist):\n",
    "    clean_content.append(text[kill:])\n",
    "\n",
    "review_df['text']=clean_content\n",
    "display(review_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62b5dd1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38,\n",
       " 34,\n",
       " 9,\n",
       " 34,\n",
       " 33,\n",
       " 13,\n",
       " 39,\n",
       " 10,\n",
       " 37,\n",
       " 30,\n",
       " 12,\n",
       " 30,\n",
       " 26,\n",
       " 37,\n",
       " 32,\n",
       " 28,\n",
       " 24,\n",
       " 16,\n",
       " 25,\n",
       " 50,\n",
       " 54,\n",
       " 40,\n",
       " 49,\n",
       " 11,\n",
       " 37,\n",
       " 11,\n",
       " 21,\n",
       " 30,\n",
       " 36,\n",
       " 35,\n",
       " 35,\n",
       " 36,\n",
       " 28,\n",
       " 13,\n",
       " 39,\n",
       " 29,\n",
       " 36,\n",
       " 10,\n",
       " 37,\n",
       " 20,\n",
       " 20,\n",
       " 44,\n",
       " 31,\n",
       " 22,\n",
       " 10,\n",
       " 26,\n",
       " 16,\n",
       " 37,\n",
       " 36,\n",
       " 36,\n",
       " 21,\n",
       " 38,\n",
       " 48,\n",
       " 30,\n",
       " 35,\n",
       " 54,\n",
       " 34,\n",
       " 14,\n",
       " 19,\n",
       " 25,\n",
       " 36,\n",
       " 30,\n",
       " 16,\n",
       " 39,\n",
       " 33,\n",
       " 32,\n",
       " 30,\n",
       " 13,\n",
       " 49,\n",
       " 12,\n",
       " 9,\n",
       " 29,\n",
       " 12,\n",
       " 35,\n",
       " 39,\n",
       " 39,\n",
       " 26,\n",
       " 39,\n",
       " 49,\n",
       " 23,\n",
       " 30,\n",
       " 39,\n",
       " 13,\n",
       " 31,\n",
       " 14,\n",
       " 30,\n",
       " 20,\n",
       " 33,\n",
       " 34,\n",
       " 21,\n",
       " 30,\n",
       " 32,\n",
       " 31,\n",
       " 33,\n",
       " 23,\n",
       " 22,\n",
       " 22,\n",
       " 18,\n",
       " 31,\n",
       " 21,\n",
       " 19,\n",
       " 13,\n",
       " 41,\n",
       " 35,\n",
       " 35,\n",
       " 37,\n",
       " 10,\n",
       " 37,\n",
       " 6,\n",
       " 69,\n",
       " 20,\n",
       " 21,\n",
       " 37,\n",
       " 40,\n",
       " 44,\n",
       " 58,\n",
       " 57,\n",
       " 33,\n",
       " 36,\n",
       " 37,\n",
       " 14,\n",
       " 40,\n",
       " 27,\n",
       " 35,\n",
       " 32,\n",
       " 32,\n",
       " 37,\n",
       " 19,\n",
       " 33,\n",
       " 30,\n",
       " 25,\n",
       " 12,\n",
       " 11,\n",
       " 21,\n",
       " 9,\n",
       " 35,\n",
       " 24,\n",
       " 27,\n",
       " 32,\n",
       " 41,\n",
       " 33,\n",
       " 37,\n",
       " 14,\n",
       " 26,\n",
       " 35,\n",
       " 32,\n",
       " 21,\n",
       " 33,\n",
       " 38,\n",
       " 19,\n",
       " 12,\n",
       " 13,\n",
       " 27,\n",
       " 14,\n",
       " 12,\n",
       " 4,\n",
       " 32,\n",
       " 41,\n",
       " 20,\n",
       " 42,\n",
       " 30,\n",
       " 4,\n",
       " 2,\n",
       " 19,\n",
       " 5,\n",
       " 43,\n",
       " 71,\n",
       " 51,\n",
       " 24,\n",
       " 18,\n",
       " 23,\n",
       " 10,\n",
       " 10,\n",
       " 31,\n",
       " 29,\n",
       " 7,\n",
       " 33,\n",
       " 35,\n",
       " 44,\n",
       " 29,\n",
       " 34,\n",
       " 31,\n",
       " 40]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titlelist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d507e708",
   "metadata": {},
   "source": [
    "url_test=\"https://www.trustpilot.com/review/www.mcmakler-finance.de?languages=de\"\n",
    "test = requests.get(url_test)\n",
    "testsoup = BeautifulSoup(test.text, 'html.parser')\n",
    "testsoup.select('div > time')\n",
    "\n",
    "testsouplist=[]\n",
    "testsouplist.append(testsoup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6667c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "datelist = [ testsoup.select('time')[d]['datetime'] for d in range(len(testsoup.select('time')))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e831fe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2022-04-08T09:47:32.000Z', '2022-04-05T21:20:44.000Z', '2022-04-05T06:41:43.000Z', '2022-03-31T11:40:46.000Z', '2022-03-31T08:44:00.000Z', '2022-03-26T17:17:19.000Z', '2022-03-26T15:55:32.000Z', '2022-03-24T09:38:53.000Z', '2022-03-22T15:19:17.000Z', '2022-03-19T18:21:11.000Z', '2022-03-16T20:29:55.000Z', '2022-03-16T15:22:53.000Z', '2022-03-11T19:18:56.000Z', '2022-03-03T15:50:40.000Z', '2022-03-03T11:23:44.000Z', '2022-03-02T16:19:43.000Z', '2022-02-27T17:38:27.000Z', '2022-02-27T10:49:39.000Z', '2022-02-25T21:45:05.000Z', '2022-02-24T17:31:14.000Z']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2022-04-08T09:47:32.000Z',\n",
       " '2022-04-05T21:20:44.000Z',\n",
       " '2022-04-05T06:41:43.000Z',\n",
       " '2022-03-31T11:40:46.000Z',\n",
       " '2022-03-31T08:44:00.000Z',\n",
       " '2022-03-26T17:17:19.000Z',\n",
       " '2022-03-26T15:55:32.000Z',\n",
       " '2022-03-24T09:38:53.000Z',\n",
       " '2022-03-22T15:19:17.000Z',\n",
       " '2022-03-19T18:21:11.000Z',\n",
       " '2022-03-16T20:29:55.000Z',\n",
       " '2022-03-16T15:22:53.000Z',\n",
       " '2022-03-11T19:18:56.000Z',\n",
       " '2022-03-03T15:50:40.000Z',\n",
       " '2022-03-03T11:23:44.000Z',\n",
       " '2022-03-02T16:19:43.000Z',\n",
       " '2022-02-27T17:38:27.000Z',\n",
       " '2022-02-27T10:49:39.000Z',\n",
       " '2022-02-25T21:45:05.000Z',\n",
       " '2022-02-24T17:31:14.000Z']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testlist=[]\n",
    "\n",
    "for lp in range(len(testsouplist)):\n",
    "    for d in range(len(testsouplist[lp].select('time'))):\n",
    "        testlist.append(testsouplist[lp].select('time')[d]['datetime'])\n",
    "\n",
    "print(testlist)\n",
    "\n",
    "a= [ testsouplist[lp].select('time')[d]['datetime'] for d in range(len(testsouplist[lp].select('time'))) for lp in range(len(testsouplist))  ]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
